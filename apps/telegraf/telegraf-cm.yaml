apiVersion: v1
data:
  telegraf.conf: |-
    # Configuration for telegraf agent
    [agent]
      ## Default data collection interval for all inputs
      interval = "10s"
      ## Rounds collection interval to 'interval'
      ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
      round_interval = true

      ## Telegraf will send metrics to outputs in batches of at most
      ## metric_batch_size metrics.
      ## This controls the size of writes that Telegraf sends to output plugins.
      metric_batch_size = 1000

      ## Maximum number of unwritten metrics per output.  Increasing this value
      ## allows for longer periods of output downtime without dropping metrics at the
      ## cost of higher maximum memory usage.
      metric_buffer_limit = 10000

      ## Collection jitter is used to jitter the collection by a random amount.
      ## Each plugin will sleep for a random time within jitter before collecting.
      ## This can be used to avoid many plugins querying things like sysfs at the
      ## same time, which can have a measurable effect on the system.
      collection_jitter = "0s"

      ## Default flushing interval for all outputs. Maximum flush_interval will be
      ## flush_interval + flush_jitter
      flush_interval = "10s"
      ## Jitter the flush interval by a random amount. This is primarily to avoid
      ## large write spikes for users running a large number of telegraf instances.
      ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
      flush_jitter = "0s"

      ## By default or when set to "0s", precision will be set to the same
      ## timestamp order as the collection interval, with the maximum being 1s.
      ##   ie, when interval = "10s", precision will be "1s"
      ##       when interval = "250ms", precision will be "1ms"
      ## Precision will NOT be used for service inputs. It is up to each individual
      ## service input to set the timestamp at the appropriate precision.
      ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
      precision = ""

      ## Log at debug level.
      # debug = false
      ## Log only error level messages.
      # quiet = false

      ## Log target controls the destination for logs and can be one of "file",
      ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
      ## is determined by the "logfile" setting.
      # logtarget = "file"

      ## Name of the file to be logged to when using the "file" logtarget.  If set to
      ## the empty string then logs are written to stderr.
      # logfile = ""

      ## The logfile will be rotated after the time interval specified.  When set
      ## to 0 no time based rotation is performed.  Logs are rotated only when
      ## written to, if there is no log activity rotation may be delayed.
      # logfile_rotation_interval = "0d"

      ## The logfile will be rotated when it becomes larger than the specified
      ## size.  When set to 0 no size based rotation is performed.
      # logfile_rotation_max_size = "0MB"

      ## Maximum number of rotated archives to keep, any older logs are deleted.
      ## If set to -1, no archives are removed.
      # logfile_rotation_max_archives = 5

      ## Pick a timezone to use when logging or type 'local' for local time.
      ## Example: America/Chicago
      # log_with_timezone = ""

      ## Override default hostname, if empty use os.Hostname()
      hostname = "brix"
      ## If set to true, do no set the "host" tag in the telegraf agent.
      omit_hostname = false
    [[outputs.influxdb_v2]]
      ## The URLs of the InfluxDB cluster nodes.
      ##
      ## Multiple URLs can be specified for a single cluster, only ONE of the
      ## urls will be written to each interval.
      ##   ex: urls = ["https://us-west-2-1.aws.cloud2.influxdata.com"]
      urls = ["$INFLUXDB_URL"]

      ## Token for authentication.
      token = "$INFLUX_TOKEN"

      ## Organization is the name of the organization you wish to write to; must exist.
      organization = "$ORGANIZATION"

      ## Destination bucket to write into.
      bucket = "server-info"

      ## The value of this tag will be used to determine the bucket.  If this
      ## tag is not set the 'bucket' option is used as the default.
      # bucket_tag = ""

      ## If true, the bucket tag will not be added to the metric.
      # exclude_bucket_tag = false

      ## Timeout for HTTP messages.
      # timeout = "5s"

      ## Additional HTTP headers
      # http_headers = {"X-Special-Header" = "Special-Value"}

      ## HTTP Proxy override, if unset values the standard proxy environment
      ## variables are consulted to determine which proxy, if any, should be used.
      # http_proxy = "http://corporate.proxy:3128"

      ## HTTP User-Agent
      # user_agent = "telegraf"

      ## Content-Encoding for write request body, can be set to "gzip" to
      ## compress body or "identity" to apply no encoding.
      # content_encoding = "gzip"

      ## Enable or disable uint support for writing uints influxdb 2.0.
      # influx_uint_support = false

      ## Optional TLS Config for use on HTTP connections.
      # tls_ca = "/etc/telegraf/ca.pem"
      # tls_cert = "/etc/telegraf/cert.pem"
      # tls_key = "/etc/telegraf/key.pem"
      ## Use TLS but skip chain & host verification
      # insecure_skip_verify = false

    [[outputs.influxdb_v2]]
      urls = ["$INFLUXDB_URL"]
      token = "$INFLUX_TOKEN"
      organization = "$ORGANIZATION"
      bucket = "my-data"
      namepass = ["http_ipinfo"]

    [[inputs.disk]]
      ## By default stats will be gathered for all mount points.
      ## Set mount_points will restrict the stats to only the specified mount points.
      mount_points = ["/data"]
      ## Ignore mount points by filesystem type.
      ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]
      fieldpass = ["free", "total",  "used"]

    [[inputs.mem]]
      fieldpass = ["total", "used"]

    [[inputs.ping]]
      fieldpass = ["percent_packet_loss", "average_response_ms", "percent_reply_loss"]
      ## Hosts to send ping packets to.
      ## Google dns / Cloudfare DNS / Level(3) DNS
      urls = ["8.8.8.8", "1.1.1.1", "209.244.0.3"]

      ## Method used for sending pings, can be either "exec" or "native".  When set
      ## to "exec" the systems ping command will be executed.  When set to "native"
      ## the plugin will send pings directly.
      ##
      ## While the default is "exec" for backwards compatibility, new deployments
      ## are encouraged to use the "native" method for improved compatibility and
      ## performance.
      method = "native"

      ## Number of ping packets to send per interval.  Corresponds to the "-c"
      ## option of the ping command.
      count = 6

      ## Time to wait between sending ping packets in seconds.  Operates like the
      ## "-i" option of the ping command.
      ping_interval = 1.0

      ## If set, the time to wait for a ping response in seconds.  Operates like
      ## the "-W" option of the ping command.
      timeout = 0.5

      # If set, the total ping deadline, in seconds.  Operates like the -w option
      # of the ping command.
      deadline = 9
      
    [[inputs.exec]]
      interval = "60m"

      # Shell/commands array
      # Full command line to executable with parameters, or a glob pattern to run all matching files.
      commands = ["/usr/local/bin/librespeed-cli --ipv4 --json"]

      ## Timeout for each command to complete.
      timeout = "2m"

      # Data format to consume.
      # NOTE json only reads numerical measurements, strings and booleans are ignored.
      data_format = "json"

      ## Tag keys is an array of keys that should be added as tags.  Matching keys
      ## are no longer saved as fields. Supports wildcard glob matching.
      tag_keys = ["server_*", "client_*"]

      # measurement name suffix (for separating different commands)
      name_suffix = "_speedtest"

    [[inputs.http]]
      interval = "60m"

      # Read formatted metrics from one or more HTTP endpoints
      urls=["https://api.ipify.org?format=json"]

      # Data format to consume.
      # NOTE json only reads numerical measurements, strings and booleans are ignored.
      data_format = "json"

      ## String fields is an array of keys that should be added as string fields.
      json_string_fields = ["ip"]

      # measurement name suffix (for separating different commands)
      name_suffix = "_ipinfo"

    [[inputs.kubernetes]]
      url = "https://$HOSTIP:10250"
      bearer_token = "/run/secrets/kubernetes.io/serviceaccount/token"
      insecure_skip_verify = true
      fieldpass = ["cpu_usage_nanocores", "memory_usage_bytes", "memory_working_set_bytes", "network_rx_bytes",
                   "network_rx_errors", "network_tx_bytes", "network_tx_errors", "fs_capacity_bytes", "fs_used_bytes"]
    
    [[inputs.mqtt_consumer]]
      servers = ["$MOSQUITTO_PORT"]

      topics = ["zigbee2mqtt/+"]
      data_format = "json"
      persistent_session = true
      qos = 1
      client_id = "telegraf_mqtt"
      tagexclude = ["topic", "host"]

      [[inputs.mqtt_consumer.topic_parsing]]  
        topic="zigbee2mqtt/+"
        measurement = "measurement/_"
        tags = "_/deviceId"

    [[processors.regex]]
      namepass = ["zigbee2mqtt"]

      [[processors.regex.tags]]
        order = 1
        key = "deviceId"
        pattern = "^(.*?)(?:_([^_]*))?$"
        replacement = "${2}"
        result_key = "name"
      
      [[processors.regex.tags]]
        order = 2
        key = "deviceId"
        pattern = "^(.*?)(?:_([^_]*))?$"
        replacement = "${1}"

kind: ConfigMap
metadata:
  creationTimestamp: null
  name: telegraf
